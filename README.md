# Proyecto: Monitor de Inteligencia de OpiniÃ³n
UEM | Sistemas Inteligentes | Proyecto final: Monitor de Inteligencia de OpiniÃ³n

# ğŸ“‹ DescripciÃ³n del Proyecto
Sistema completo para analizar opiniones y reseÃ±as de Amazon EspaÃ±a mediante tÃ©cnicas de NLP y visualizaciÃ³n de datos. Este proyecto implementa un pipeline end-to-end que incluye web scraping, preprocesamiento de texto, anÃ¡lisis de sentimiento y visualizaciÃ³n de resultados.

# ğŸ‘¥ Equipo
- RubÃ©n: Web Scraping, AnÃ¡lisis de Frecuencia, CoordinaciÃ³n
- Juanes: Preprocesamiento NLP, VisualizaciÃ³n, DocumentaciÃ³n

# ğŸ—ï¸ Estructura del Proyecto
```
monitor_inteligencia_opinion/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Datos crudos del scraping
â”‚   â””â”€â”€ processed/        # Datos procesados y analizados
â”œâ”€â”€ notebooks/            # Jupyter notebooks por fase
â”‚   â”œâ”€â”€ 1_scraping.ipynb
â”‚   â”œâ”€â”€ 2_preprocesamiento.ipynb
â”‚   â”œâ”€â”€ 3_analisis.ipynb
â”‚   â””â”€â”€ 4_visualizacion.ipynb
â”œâ”€â”€ scripts/              # Scripts Python reutilizables
â”‚   â”œâ”€â”€ scraper.py
â”‚   â””â”€â”€ preprocessing.py
â”œâ”€â”€ visualizations/       # GrÃ¡ficos y visualizaciones
â”œâ”€â”€ requirements.txt      # Dependencias del proyecto
â””â”€â”€ README.md            # Este archivo
```

# ğŸ› ï¸ PreparaciÃ³n del Entorno
## Requisitos Previos
- Python 3.8 o superior
- Git (opcional, para clonar el repositorio)
- 500 MB de espacio libre en disco

## OpciÃ³n 1: Entorno Local (Recomendado)
### Paso 1: Clonar o descargar el proyecto
```
# Si usas Git
git clone <url-del-repositorio>
cd monitor_inteligencia_opinion
```
# O descargar manualmente y descomprimir
Paso 2: Crear y activar entorno virtual
bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
Paso 3: Instalar dependencias
bash
pip install --upgrade pip
pip install -r requirements.txt
Paso 4: Descargar recursos de NLTK
bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
Paso 5: Verificar instalaciÃ³n
bash
python -c "import pandas, nltk, textblob; print('âœ“ Todas las dependencias estÃ¡n instaladas')"
OpciÃ³n 2: Google Colab (Sin instalaciÃ³n local)
Subir todos los archivos del proyecto a Google Drive

Abrir Colab: colab.research.google.com

Montar Google Drive:

python
from google.colab import drive
drive.mount('/content/drive')
Navegar al directorio del proyecto

Instalar dependencias en Colab:

```
!pip install pandas nltk textblob beautifulsoup4 wordcloud plotly
!python -m nltk.downloader punkt stopwords
```

ğŸ§ª Pruebas y VerificaciÃ³n del Proyecto
VerificaciÃ³n Paso a Paso
Test 1: Verificar estructura del proyecto
```
# En la raÃ­z del proyecto, ejecutar:
python -c "
import os
required_dirs = ['data/raw', 'data/processed', 'notebooks', 'scripts', 'visualizations']
required_files = ['requirements.txt', 'notebooks/1_scraping.ipynb', 'scripts/scraper.py']
for dir in required_dirs:
    os.makedirs(dir, exist_ok=True)
    print(f'âœ“ Directorio {dir} existe')
for file in required_files:
    if os.path.exists(file):
        print(f'âœ“ Archivo {file} existe')
    else:
        print(f'âœ— Archivo {file} no encontrado')
```
Test 2: Ejecutar scraping (Fase 1)

# OpciÃ³n A: Usar el notebook
```
jupyter notebook notebooks/1_scraping.ipynb
```
# Ejecutar todas las celdas (Cell â†’ Run All)

# OpciÃ³n B: Usar el script directamente
```
python scripts/scraper.py
```
Resultado esperado: Archivo data/raw/reviews_amazon_raw.csv con 50-100 reseÃ±as.

Test 3: Verificar datos extraÃ­dos
```
python -c "
import pandas as pd
try:
    df = pd.read_csv('data/raw/reviews_amazon_raw.csv')
    print(f'âœ“ Dataset cargado: {len(df)} reseÃ±as')
    print(f'âœ“ Columnas: {list(df.columns)}')
    print(f'âœ“ Muestra de datos:')
    print(df[['usuario', 'puntuacion']].head(3))
except Exception as e:
    print(f'âœ— Error: {e}')
```
Test 4: Ejecutar preprocesamiento (Fase 2)
```
python scripts/preprocessing.py
```
Resultado esperado: Archivo data/processed/reviews_preprocessed.csv con columnas adicionales de texto procesado.

Test 5: Verificar preprocesamiento
```
python -c "
import pandas as pd
df = pd.read_csv('data/processed/reviews_preprocessed.csv')
print('âœ“ Columnas en dataset procesado:')
for col in df.columns:
    if 'texto' in col.lower():
        print(f'  - {col}')
print(f'\\nâœ“ Ejemplo de procesamiento:')
print(f'Texto original: {df.iloc[0][\"texto_original\"][:100]}...')
print(f'Texto limpio: {df.iloc[0][\"texto_limpio\"][:100]}...')
```
Test 6: Verificar anÃ¡lisis completo
```
# Ejecutar el notebook 3_analisis.ipynb completo
# Verificar que se generen:
# - data/processed/reviews_with_sentiment.csv
# - data/processed/analisis_stats.json
# - data/processed/top_palabras.csv
```
Test 7: Verificar visualizaciones
```
# Ejecutar el notebook 4_visualizacion.ipynb completo
# Verificar que se generen en visualizations/:
ls visualizations/
# DeberÃ­an aparecer:
# - wordcloud.png
# - top10_palabras.png
# - distribucion_sentimientos.png
# - informe_final.png
```
ğŸš€ CÃ³mo Ejecutar el Proyecto Completo
MÃ©todo 1: EjecuciÃ³n secuencial (Recomendado para primera vez)
```
# 1. Activar entorno virtual
```
source venv/bin/activate  # o venv\Scripts\activate en Windows
```
# 2. Ejecutar fase por fase
```
python scripts/scraper.py
python scripts/preprocessing.py
jupyter notebook notebooks/3_analisis.ipynb  # Ejecutar todas las celdas
jupyter notebook notebooks/4_visualizacion.ipynb  # Ejecutar todas las celdas
```
MÃ©todo 2: Pipeline automatizado

# Crear script run_pipeline.py
```
python -c "
import subprocess
import sys

def run_phase(phase_name, command):
    print(f'\\n{'='*60}')
    print(f'Ejecutando {phase_name}')
    print(f'{'='*60}')
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    if result.returncode == 0:
        print(f'âœ“ {phase_name} completado')
        return True
    else:
        print(f'âœ— Error en {phase_name}:')
        print(result.stderr)
        return False
```
# Ejecutar pipeline
```
phases = [
    ('Scraping', 'python scripts/scraper.py'),
    ('Preprocesamiento', 'python scripts/preprocessing.py'),
    ('AnÃ¡lisis', 'jupyter nbconvert --to notebook --execute notebooks/3_analisis.ipynb'),
    ('VisualizaciÃ³n', 'jupyter nbconvert --to notebook --execute notebooks/4_visualizacion.ipynb')
]

for phase_name, command in phases:
    if not run_phase(phase_name, command):
        print('Pipeline interrumpido')
        sys.exit(1)

print('\\nâœ… Pipeline completado exitosamente')
```
MÃ©todo 3: Usar Jupyter Notebooks interactivamente
```
# Iniciar Jupyter
jupyter notebook

# En el navegador, ejecutar en orden:
# 1. notebooks/1_scraping.ipynb
# 2. notebooks/2_preprocesamiento.ipynb
# 3. notebooks/3_analisis.ipynb
# 4. notebooks/4_visualizacion.ipynb

# âœ… Criterios de VerificaciÃ³n Final
Para confirmar que el proyecto funciona correctamente, verificar:

Requisitos MÃ­nimos:
- Dataset con al menos 50 reseÃ±as (data/raw/reviews_amazon_raw.csv)
- Preprocesamiento aplicado (texto_limpio, texto_sin_stopwords)
- AnÃ¡lisis de frecuencia (Top 10 palabras en top_palabras.csv)
- AnÃ¡lisis de sentimiento (polarity, subjectivity, sentiment)
- Al menos 3 visualizaciones generadas

VerificaciÃ³n AutomÃ¡tica:
```
python -c "
import pandas as pd
import os
import json

print('VerificaciÃ³n del proyecto...')
print('='*50)
```

# 1. Verificar dataset
```
try:
    df_raw = pd.read_csv('data/raw/reviews_amazon_raw.csv')
    print(f'âœ“ Dataset raw: {len(df_raw)} reseÃ±as')
    assert len(df_raw) >= 50, 'Menos de 50 reseÃ±as'
except Exception as e:
    print(f'âœ— Error dataset raw: {e}')
```

# 2. Verificar preprocesamiento
```
try:
    df_proc = pd.read_csv('data/processed/reviews_preprocessed.csv')
    required_cols = ['texto_limpio', 'texto_sin_stopwords']
    for col in required_cols:
        assert col in df_proc.columns, f'Falta columna {col}'
    print('âœ“ Preprocesamiento completo')
except Exception as e:
    print(f'âœ— Error preprocesamiento: {e}')
```
# 3. Verificar anÃ¡lisis
```
try:
    df_sent = pd.read_csv('data/processed/reviews_with_sentiment.csv')
    assert 'sentiment' in df_sent.columns, 'Falta anÃ¡lisis de sentimiento'
    print('âœ“ AnÃ¡lisis de sentimiento completado')
except Exception as e:
    print(f'âœ— Error anÃ¡lisis: {e}')
```
# 4. Verificar visualizaciones
```
viz_files = ['wordcloud.png', 'top10_palabras.png', 'distribucion_sentimientos.png']
for viz in viz_files:
    if os.path.exists(f'visualizations/{viz}'):
        print(f'âœ“ VisualizaciÃ³n {viz} generada')
    else:
        print(f'âœ— Falta visualizaciÃ³n {viz}')

print('\\n' + '='*50)
print('VerificaciÃ³n completada')
```
# ğŸ› SoluciÃ³n de Problemas Comunes
Problema 1: Error en la instalaciÃ³n de dependencias

# Si hay errores de versiÃ³n
```
pip install --upgrade pip setuptools wheel
```
# Si hay problemas con NLTK
```
python -m nltk.downloader all
Problema 2: Scraping bloqueado
```
# Editar scripts/scraper.py y aumentar delays
```
time.sleep(random.uniform(3, 5))  # En lugar de 1-3
Problema 3: Memoria insuficiente en notebooks
```
# Reducir tamaÃ±o de dataset
# En scraping, cambiar pages=2 a pages=1
Problema 4: Caracteres especiales mal codificados

# Asegurar encoding UTF-8
```
df.to_csv('archivo.csv', index=False, encoding='utf-8-sig')
```
# ğŸ“Š Resultados Esperados
Archivos Generados:
```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ reviews_amazon_raw.csv          # 50-100 reseÃ±as crudas
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ reviews_preprocessed.csv        # Textos procesados
â”‚   â”œâ”€â”€ reviews_with_sentiment.csv      # AnÃ¡lisis completo
â”‚   â”œâ”€â”€ top_palabras.csv               # Frecuencia de palabras
â”‚   â””â”€â”€ analisis_stats.json            # EstadÃ­sticas clave

visualizations/
â”œâ”€â”€ wordcloud.png                      # Nube de palabras
â”œâ”€â”€ top10_palabras.png                 # GrÃ¡fico de barras
â”œâ”€â”€ distribucion_sentimientos.png      # GrÃ¡fico circular
â”œâ”€â”€ puntuacion_vs_sentimiento.png      # GrÃ¡fico de dispersiÃ³n
â”œâ”€â”€ analisis_adicional_1.png          # GrÃ¡ficos adicionales
â”œâ”€â”€ heatmap_palabras_sentimiento.png  # Heatmap
â”œâ”€â”€ informe_final.png                 # Informe visual completo
â””â”€â”€ dashboard_interactivo.html        # Dashboard interactivo
```
---

# MÃ©tricas de Calidad:
- Coverage: 100% de las fases implementadas
- Reproducibilidad: Pipeline completamente automatizado
- DocumentaciÃ³n: CÃ³digo comentado y README completo
- Visualizaciones: GrÃ¡ficos profesionales y informativos

---

# ğŸ“ Notas Finales
Este proyecto estÃ¡ completamente desarrollado y probado, con una distribuciÃ³n equitativa del trabajo entre RubÃ©n y Juanes. Cada fase incluye cÃ³digo funcional, documentaciÃ³n y resultados verificables.

---

# CaracterÃ­sticas destacadas:
## âœ… Web scraping Ã©tico con delays y User-Agents
## âœ… Pipeline completo de NLP en espaÃ±ol
## âœ… AnÃ¡lisis de sentimiento con TextBlob
## âœ… Visualizaciones profesionales
## âœ… CÃ³digo modular y reutilizable
## âœ… DocumentaciÃ³n completa
## âœ… Tests de verificaciÃ³n incluidos

---

Para cualquier problema o consulta:
- Revisar la secciÃ³n de soluciÃ³n de problemas
- Verificar que todas las dependencias estÃ¡n instaladas
- Ejecutar los tests de verificaciÃ³n
- Consultar los notebooks de ejemplo

---

Licencia: Proyecto educativo - Uso acadÃ©mico
Fecha: Diciembre 2025
Asignatura: Sistemas Inteligentes - Universidad Europea