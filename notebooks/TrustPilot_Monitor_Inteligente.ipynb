{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ TrustPilot Monitor Inteligente de Opini√≥n\n",
                "## üíé Herramienta de Inteligencia Comercial Unificada y Mejorada\n",
                "\n",
                "Este notebook representa la uni√≥n definitiva de los prototipos iniciales, optimizado para ofrecer una soluci√≥n robusta, escalable y profesional para el an√°lisis de la reputaci√≥n digital.\n",
                "\n",
                "### üë§ Cr√©ditos y Autor√≠a:\n",
                "- **Base del Proyecto**: [Juanes] (MONITOR_INTELIGENCIA_OPINION / Prototipos Iniciales)\n",
                "- **Mejoras y Nuevos M√≥dulos**: [Rub√©n] (B√∫squeda din√°mica, Modo Stealth, IA H√≠brida, Dashboard Temporal)\n",
                "\n",
                "### üî¨ Fases del Monitor:\n",
                "1.  üì• **ADQUISICI√ìN DE DATOS**: Scraping inteligente con rotaci√≥n de identidad y b√∫squeda din√°mica. [Base: Juanes | Mejoras: Rub√©n]\n",
                "2.  üßπ **PREPROCESAMIENTO NLP**: Limpieza profunda y tokenizaci√≥n de textos en espa√±ol. [Autor: Juanes]\n",
                "3.  üíé **AN√ÅLISIS DE SENTIMIENTO**: Motor h√≠brido diccionario + IA avanzada. [Base: Juanes | Refuerzo AI: Rub√©n]\n",
                "4.  üìä **DASHBOARD BI**: Visualizaci√≥n de impacto para toma de decisiones. [Visuales: Juanes | Eje Temporal: Rub√©n]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "fase-0"
            },
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# FASE 0: PREPARACI√ìN DEL ENTORNO\n",
                "# [Mejora Compatibilidad Rub√©n / Original Juanes]\n",
                "# =============================================================================\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "print(\"üîß Inicializando entorno del monitor...\")\n",
                "\n",
                "def setup_environment():\n",
                "    # Listado de librer√≠as esenciales unificadas\n",
                "    libs = [\n",
                "        \"requests\", \"beautifulsoup4\", \"lxml\", \"nltk\", \"textblob\", \n",
                "        \"googletrans==4.0.0-rc1\", \"wordcloud\", \"matplotlib\", \n",
                "        \"seaborn\", \"plotly\", \"fake-useragent\", \"pandas\", \n",
                "        \"numpy\", \"regex\", \"tqdm\", \"spacy\"\n",
                "    ]\n",
                "    \n",
                "    for lib in libs:\n",
                "        try:\n",
                "            # [Rub√©n] Uso de sys.executable para garantizar instalaci√≥n en el kernel activo\n",
                "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", lib, \"-q\"])\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    # Descarga de recursos NLP\n",
                "    import nltk\n",
                "    nltk.download(['punkt', 'stopwords', 'punkt_tab'], quiet=True)\n",
                "    \n",
                "    try:\n",
                "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"es_core_news_sm\", \"-q\"])\n",
                "    except:\n",
                "        pass\n",
                "\n",
                "setup_environment()\n",
                "print(\"‚úÖ Entorno listo para procesamiento.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import requests\n",
                "import re\n",
                "import time\n",
                "import random\n",
                "from datetime import datetime\n",
                "from typing import List, Dict, Optional\n",
                "from collections import Counter\n",
                "from bs4 import BeautifulSoup\n",
                "from fake_useragent import UserAgent\n",
                "from textblob import TextBlob\n",
                "from googletrans import Translator\n",
                "from wordcloud import WordCloud\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.express as px\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "from tqdm import tqdm\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "plt.style.use('seaborn-v0_8')\n",
                "print(\"üìö Librer√≠as de an√°lisis cargadas.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üì• FASE 1: SCRAPER INTELIGENTE DE TRUSTPILOT\n",
                "### [Base: Juanes | Mejoras Rub√©n: B√∫squeda y Modo Stealth]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "scraper"
            },
            "outputs": [],
            "source": [
                "class TrustpilotScraper:\n",
                "    def __init__(self, business_query: str = None, max_pages: int = 5):\n",
                "        self.query = business_query\n",
                "        self.max_pages = max_pages\n",
                "        self.ua = UserAgent() # [Rub√©n] Rotaci√≥n de identidad\n",
                "        self.session = requests.Session()\n",
                "        self.base_url = \"https://es.trustpilot.com\"\n",
                "        self.target_url = None\n",
                "        self.reviews_data = []\n",
                "\n",
                "    def _get_headers(self):\n",
                "        \"\"\"[Rub√©n] Modo Stealth: Encabezados realistas aleatorios.\"\"\"\n",
                "        return {\n",
                "            'User-Agent': self.ua.random,\n",
                "            'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',\n",
                "            'Referer': 'https://www.google.com/'\n",
                "        }\n",
                "\n",
                "    def search_business(self) -> bool:\n",
                "        \"\"\"[Rub√©n] B√∫squeda autom√°tica por palabra clave.\"\"\"\n",
                "        if not self.query: return False\n",
                "        if \"trustpilot.com/review/\" in self.query:\n",
                "            self.target_url = self.query\n",
                "            return True\n",
                "\n",
                "        print(f\"üîç Buscando: '{self.query}'...\")\n",
                "        try:\n",
                "            s_url = f\"{self.base_url}/search?query={self.query.replace(' ', '+')}\"\n",
                "            res = self.session.get(s_url, headers=self._get_headers())\n",
                "            soup = BeautifulSoup(res.content, 'html.parser')\n",
                "            link = soup.select_one('a[data-business-unit-card-link=\"true\"]')\n",
                "            if link: \n",
                "                self.target_url = self.base_url + link['href']\n",
                "                print(f\"‚úÖ Encontrado: {self.target_url}\")\n",
                "                return True\n",
                "        except: pass\n",
                "        return False\n",
                "\n",
                "    def safe_extract(self, element, select_list: List[str], attr: str = None) -> str:\n",
                "        \"\"\"[Juanes] L√≥gica resiliente ante cambios de HTML.\"\"\"\n",
                "        for selector in select_list:\n",
                "            found = element.select_one(selector)\n",
                "            if found:\n",
                "                return found.get(attr, \"\") if attr else found.get_text(strip=True)\n",
                "        return \"\"\n",
                "\n",
                "    def run(self) -> pd.DataFrame:\n",
                "        if not self.target_url and not self.search_business(): return pd.DataFrame()\n",
                "        \n",
                "        for page in range(1, self.max_pages + 1):\n",
                "            print(f\"üìÑ P√°gina {page}...\")\n",
                "            time.sleep(random.uniform(2, 4)) # [Rub√©n] Delay antidetect\n",
                "            try:\n",
                "                res = self.session.get(f\"{self.target_url}?page={page}\", headers=self._get_headers())\n",
                "                soup = BeautifulSoup(res.content, 'html.parser')\n",
                "                cards = soup.select('article[data-service-review-card-paper=\"true\"]')\n",
                "                \n",
                "                for card in cards:\n",
                "                    text = self.safe_extract(card, ['p[data-service-review-text-typography=\"true\"]', 'p[data-review-content-typography=\"true\"]'])\n",
                "                    if not text: continue\n",
                "                    \n",
                "                    rating_alt = self.safe_extract(card, ['.styles_reviewHeader__iU9_n img'], 'alt')\n",
                "                    rating = re.search(r'\\d', rating_alt).group() if rating_alt else \"0\"\n",
                "                    date_iso = self.safe_extract(card, ['time'], 'datetime')\n",
                "                    \n",
                "                    self.reviews_data.append({\n",
                "                        'texto': text,\n",
                "                        'puntuacion': int(rating),\n",
                "                        'fecha': date_iso[:10] if date_iso else datetime.now().strftime('%Y-%m-%d')\n",
                "                    })\n",
                "            except: break\n",
                "        return pd.DataFrame(self.reviews_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# [Rub√©n] Ejecuci√≥n del Scraper\n",
                "empresa = input(\"Ingrese nombre de empresa o URL de Trustpilot: \") or \"Amazon Spain\"\n",
                "df_raw = TrustpilotScraper(empresa, max_pages=3).run()\n",
                "\n",
                "if df_raw.empty:\n",
                "    # Dataset de cortes√≠a para pruebas r√°pidas si no hay internet o bloqueo\n",
                "    df_raw = pd.DataFrame({'texto': [\"Muy bueno\", \"Mal servicio\", \"Perfecto\", \"No lleg√≥\"], 'puntuacion': [5, 1, 5, 1], 'fecha': [\"2024-01-01\"]*4})\n",
                "\n",
                "print(f\"üìå {len(df_raw)} rese√±as capturadas.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üßπ FASE 2: PREPROCESAMIENTO NLP\n",
                "### [Autor Principal: Juanes]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "preprocessing"
            },
            "outputs": [],
            "source": [
                "class TextCleaner:\n",
                "    def __init__(self):\n",
                "        self.stop = set(stopwords.words('spanish'))\n",
                "        self.stop.update(['amazon', 'servicio', 'producto', 'pedido', 'env√≠o'])\n",
                "\n",
                "    def clean(self, text):\n",
                "        # [Juanes] Normalizaci√≥n y eliminaci√≥n de ruido\n",
                "        text = text.lower()\n",
                "        text = re.sub(r'[^a-z√°√©√≠√≥√∫√º√±\\s]', '', text)\n",
                "        tokens = word_tokenize(text)\n",
                "        return ' '.join([t for t in tokens if t not in self.stop and len(t) > 2])\n",
                "\n",
                "cleaner = TextCleaner()\n",
                "df_proc = df_raw.copy()\n",
                "df_proc['texto_limpio'] = df_proc['texto'].apply(cleaner.clean)\n",
                "print(\"üßπ Textos procesados y limpios.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üíé FASE 3: AN√ÅLISIS DE SENTIMIENTO\n",
                "### [Base Juanes | Mejora AI Rub√©n]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "sentiment"
            },
            "outputs": [],
            "source": [
                "class SentimentEngine:\n",
                "    def __init__(self):\n",
                "        # [Juanes] Diccionarios de referencia r√†pida\n",
                "        self.pos = {'excelente', 'perfecto', 'bueno', 'r√°pido', 'recomiendo'}\n",
                "        self.neg = {'malo', 'p√©simo', 'lento', 'estafa', 'horrible'}\n",
                "        self.trans = Translator()\n",
                "\n",
                "    def analyze(self, text):\n",
                "        words = set(text.split())\n",
                "        p_score = len(words & self.pos)\n",
                "        n_score = len(words & self.neg)\n",
                "        \n",
                "        # [Rub√©n] Fallback a IA avanzada si el texto es descriptivo\n",
                "        if len(text) > 50 and p_score == n_score:\n",
                "            try:\n",
                "                en_text = self.trans.translate(text, dest='en').text\n",
                "                score = TextBlob(en_text).sentiment.polarity\n",
                "                return 'positivo' if score > 0 else ('negativo' if score < 0 else 'neutral')\n",
                "            except: pass\n",
                "            \n",
                "        return 'positivo' if p_score > n_score else ('negativo' if n_score > p_score else 'neutral')\n",
                "\n",
                "engine = SentimentEngine()\n",
                "df_proc['sentimiento'] = df_proc['texto_limpio'].apply(engine.analyze)\n",
                "print(df_proc['sentimiento'].value_counts(normalize=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä FASE 4: VISUALIZACI√ìN GR√ÅFICA (BI)\n",
                "### [Dise√±o Juanes | Rub√©n: Visi√≥n Temporal]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "bi"
            },
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 10))\n",
                "\n",
                "# 1. Distribuci√≥n Sentimiento [Juanes]\n",
                "plt.subplot(2, 2, 1)\n",
                "sns.countplot(data=df_proc, x='sentimiento', palette='viridis')\n",
                "plt.title(\"Distribuci√≥n de Sentimiento [Juanes]\")\n",
                "\n",
                "# 2. Nube de Palabras [Juanes]\n",
                "plt.subplot(2, 2, 2)\n",
                "wc = WordCloud(background_color='white').generate(' '.join(df_proc['texto_limpio']))\n",
                "plt.imshow(wc)\n",
                "plt.axis('off')\n",
                "plt.title(\"Nube de Temas [Juanes]\")\n",
                "\n",
                "# 3. Tendencia Temporal [Rub√©n]\n",
                "plt.subplot(2, 2, 3)\n",
                "df_proc['fecha'] = pd.to_datetime(df_proc['fecha'])\n",
                "df_proc.groupby('fecha')['puntuacion'].mean().plot(marker='o', color='red')\n",
                "plt.title(\"Evoluci√≥n de Satisfacci√≥n [Rub√©n]\")\n",
                "\n",
                "# 4. Consistencia IA vs Estrellas [Rub√©n]\n",
                "plt.subplot(2, 2, 4)\n",
                "sns.boxplot(data=df_proc, x='sentimiento', y='puntuacion')\n",
                "plt.title(\"Consistencia IA vs Rating [Rub√©n]\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}