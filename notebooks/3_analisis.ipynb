{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791dbea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:23:00.118002Z",
     "iopub.status.busy": "2025-12-21T23:23:00.117103Z",
     "iopub.status.idle": "2025-12-21T23:23:02.193216Z",
     "shell.execute_reply": "2025-12-21T23:23:02.192208Z"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos procesados...\n",
      "Dataset cargado: 210 reseñas\n",
      "Columnas disponibles: ['usuario', 'puntuacion', 'fecha', 'titulo', 'texto_comentario', 'fecha_sistema', 'texto_limpio', 'texto_original', 'texto_sin_stopwords', 'texto_comentario_limpio', 'texto_comentario_sin_stopwords', 'tokens', 'tokens_sin_stopwords', 'num_palabras', 'num_palabras_limpias', 'longitud_comentario', 'conteo_palabras_unicas']\n",
      "\n",
      "============================================================\n",
      "1. ANÁLISIS DE FRECUENCIA DE PALABRAS\n",
      "============================================================\n",
      "Total de palabras únicas: 513\n",
      "Total de tokens: 2472\n",
      "\n",
      "Top 20 palabras más frecuentes:\n",
      "----------------------------------------\n",
      " 1. texto                :   60 apariciones\n",
      " 2. disponible           :   60 apariciones\n",
      " 3. cliente              :   39 apariciones\n",
      " 4. atencion             :   33 apariciones\n",
      " 5. dias                 :   33 apariciones\n",
      " 6. entrega              :   30 apariciones\n",
      " 7. dicen                :   27 apariciones\n",
      " 8. comprado             :   24 apariciones\n",
      " 9. dia                  :   24 apariciones\n",
      "10. pedido               :   21 apariciones\n",
      "11. dos                  :   18 apariciones\n",
      "12. servicio             :   18 apariciones\n",
      "13. despues              :   18 apariciones\n",
      "14. devolucion           :   18 apariciones\n",
      "15. compre               :   18 apariciones\n",
      "16. compra               :   15 apariciones\n",
      "17. llevo                :   15 apariciones\n",
      "18. paquete              :   15 apariciones\n",
      "19. entregado            :   12 apariciones\n",
      "20. suscripcion          :   12 apariciones\n",
      "\n",
      "ANÁLISIS DE N-GRAMAS\n",
      "----------------------------------------\n",
      "\n",
      "Top 10 bigramas más frecuentes:\n",
      " 1. texto disponible               :  60\n",
      " 2. disponible texto               :  57\n",
      " 3. atencion cliente               :  33\n",
      " 4. servicio atencion              :  12\n",
      " 5. devolucion nunca               :   9\n",
      " 6. pedido entregado               :   6\n",
      " 7. aun asi                        :   6\n",
      " 8. puedo poner                    :   6\n",
      " 9. tres dias                      :   6\n",
      "10. contacto servicio              :   6\n",
      "\n",
      "Top 10 trigramas más frecuentes:\n",
      " 1. texto disponible texto                   :  57\n",
      " 2. disponible texto disponible              :  57\n",
      " 3. servicio atencion cliente                :  12\n",
      " 4. contacto servicio atencion               :   6\n",
      " 5. atencion cliente atencion                :   6\n",
      " 6. cliente atencion cliente                 :   6\n",
      " 7. habia nadie casa                         :   6\n",
      " 8. entrega funciona bastante                :   6\n",
      " 9. comprado pack canape                     :   3\n",
      "10. pack canape colchon                      :   3\n",
      "\n",
      "ANÁLISIS DE FRECUENCIA POR PUNTUACIÓN\n",
      "----------------------------------------\n",
      "Reseñas positivas (4-5 estrellas): 8\n",
      "Reseñas negativas (1-2 estrellas): 194\n",
      "\n",
      "Top 5 palabras en reseñas POSITIVAS:\n",
      "  texto          :   8\n",
      "  disponible     :   8\n",
      "\n",
      "Top 5 palabras en reseñas NEGATIVAS:\n",
      "  texto          :  50\n",
      "  disponible     :  50\n",
      "  cliente        :  39\n",
      "  atencion       :  33\n",
      "  dias           :  33\n",
      "\n",
      "============================================================\n",
      "2. ANÁLISIS DE SENTIMIENTO\n",
      "============================================================\n",
      "Analizando sentimiento de las reseñas...\n",
      "  Procesando reseña 0/210...\n",
      "  Procesando reseña 10/210...\n",
      "  Procesando reseña 20/210...\n",
      "  Procesando reseña 30/210...\n",
      "  Procesando reseña 40/210...\n",
      "  Procesando reseña 50/210...\n",
      "  Procesando reseña 60/210...\n",
      "  Procesando reseña 70/210...\n",
      "  Procesando reseña 80/210...\n",
      "  Procesando reseña 90/210...\n",
      "  Procesando reseña 100/210...\n",
      "  Procesando reseña 110/210...\n",
      "  Procesando reseña 120/210...\n",
      "  Procesando reseña 130/210...\n",
      "  Procesando reseña 140/210...\n",
      "  Procesando reseña 150/210...\n",
      "  Procesando reseña 160/210...\n",
      "  Procesando reseña 170/210...\n",
      "  Procesando reseña 180/210...\n",
      "  Procesando reseña 190/210...\n",
      "  Procesando reseña 200/210...\n",
      "\n",
      "ESTADÍSTICAS DE ANÁLISIS DE SENTIMIENTO\n",
      "----------------------------------------\n",
      "\n",
      "Distribución de sentimientos:\n",
      "  neutral   : 204 reseñas (97.1%)\n",
      "  negativo  :   6 reseñas (2.9%)\n",
      "\n",
      "Polaridad promedio: -0.020\n",
      "Subjetividad promedio: 0.065\n",
      "\n",
      "COMPARACIÓN SENTIMIENTO VS PUNTUACIÓN\n",
      "----------------------------------------\n",
      "\n",
      "Tabla cruzada (Puntuación × Sentimiento):\n",
      "sentiment   negativo  neutral\n",
      "puntuacion                   \n",
      "1                  6      176\n",
      "2                  0       12\n",
      "3                  0        8\n",
      "5                  0        8\n",
      "\n",
      "Correlación puntuación-polaridad: 0.048\n",
      "\n",
      "============================================================\n",
      "3. ANÁLISIS ADICIONALES DE VALOR\n",
      "============================================================\n",
      "\n",
      "ANÁLISIS DE EMOCIONES BÁSICO\n",
      "----------------------------------------\n",
      "\n",
      "Distribución de emociones detectadas:\n",
      "  sin_emocion_detectada    :  96 reseñas (45.7%)\n",
      "  neutras                  :  78 reseñas (37.1%)\n",
      "  negativas                :  27 reseñas (12.9%)\n",
      "  positivas                :   9 reseñas (4.3%)\n",
      "\n",
      "ANÁLISIS DE LONGITUD VS SENTIMIENTO\n",
      "----------------------------------------\n",
      "\n",
      "Estadísticas por tipo de sentimiento:\n",
      "\n",
      "NEGATIVO:\n",
      "  Número de reseñas: 6\n",
      "  Longitud promedio: 128 caracteres\n",
      "  Palabras promedio: 16\n",
      "  Puntuación promedio: 1.0\n",
      "\n",
      "NEUTRAL:\n",
      "  Número de reseñas: 204\n",
      "  Longitud promedio: 88 caracteres\n",
      "  Palabras promedio: 12\n",
      "  Puntuación promedio: 1.3\n",
      "\n",
      "Guardando resultados del análisis...\n",
      "✓ Dataset con sentimiento guardado: ../data/processed/reviews_with_sentiment.csv\n",
      "✓ Estadísticas guardadas: ../data/processed/analisis_stats.json\n",
      "\n",
      "Preparando datos para visualización...\n",
      "✓ Top 50 palabras guardadas: ../data/processed/top_palabras.csv\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DEL ANÁLISIS\n",
      "================================================================================\n",
      "✓ Reseñas analizadas: 210\n",
      "✓ Sentimiento predominante: neutral\n",
      "✓ Polaridad promedio: -0.020\n",
      "✓ Palabras únicas identificadas: 513\n",
      "✓ Archivos generados:\n",
      "   - reviews_with_sentiment.csv (dataset completo con análisis)\n",
      "   - top_palabras.csv (frecuencia de palabras)\n",
      "   - analisis_stats.json (estadísticas clave)\n",
      "\n",
      "El análisis está listo para la fase de visualización.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # FASE 3: Análisis de Valor\n",
    "# ## Rubén (Organizador) - Análisis de Frecuencia y Sentimiento\n",
    "\n",
    "# %%\n",
    "# Instalación de dependencias adicionales\n",
    "# !pip install textblob wordcloud\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# %%\n",
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# %%\n",
    "# Cargar datos procesados\n",
    "print(\"Cargando datos procesados...\")\n",
    "df = pd.read_csv('../data/processed/dataset_clean.csv')\n",
    "print(f\"Dataset cargado: {len(df)} reseñas\")\n",
    "print(f\"Columnas disponibles: {list(df.columns)}\")\n",
    "\n",
    "# %%\n",
    "# 1. ANÁLISIS DE FRECUENCIA DE PALABRAS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. ANÁLISIS DE FRECUENCIA DE PALABRAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combinar todos los textos sin stopwords\n",
    "all_text = ' '.join(df['texto_sin_stopwords'].dropna().astype(str))\n",
    "\n",
    "# Tokenizar y contar frecuencia\n",
    "tokens = all_text.split()\n",
    "word_freq = Counter(tokens)\n",
    "\n",
    "print(f\"Total de palabras únicas: {len(word_freq)}\")\n",
    "print(f\"Total de tokens: {len(tokens)}\")\n",
    "\n",
    "# Top 20 palabras más frecuentes\n",
    "top_n = 20\n",
    "top_words = word_freq.most_common(top_n)\n",
    "\n",
    "print(f\"\\nTop {top_n} palabras más frecuentes:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (word, count) in enumerate(top_words, 1):\n",
    "    print(f\"{i:2d}. {word:20s} : {count:4d} apariciones\")\n",
    "\n",
    "# %%\n",
    "# Análisis por n-gramas (bigramas y trigramas)\n",
    "print(\"\\nANÁLISIS DE N-GRAMAS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "# Crear bigramas\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq = Counter(bigrams)\n",
    "\n",
    "# Top 10 bigramas\n",
    "print(\"\\nTop 10 bigramas más frecuentes:\")\n",
    "for i, (bigram, count) in enumerate(bigram_freq.most_common(10), 1):\n",
    "    print(f\"{i:2d}. {' '.join(bigram):30s} : {count:3d}\")\n",
    "\n",
    "# Crear trigramas\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "trigram_freq = Counter(trigrams)\n",
    "\n",
    "# Top 10 trigramas\n",
    "print(\"\\nTop 10 trigramas más frecuentes:\")\n",
    "for i, (trigram, count) in enumerate(trigram_freq.most_common(10), 1):\n",
    "    print(f\"{i:2d}. {' '.join(trigram):40s} : {count:3d}\")\n",
    "\n",
    "# %%\n",
    "# Análisis de frecuencia por puntuación\n",
    "print(\"\\nANÁLISIS DE FRECUENCIA POR PUNTUACIÓN\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'puntuacion' in df.columns and df['puntuacion'].notna().any():\n",
    "    # Separar reseñas positivas (4-5 estrellas) vs negativas (1-2 estrellas)\n",
    "    df_pos = df[df['puntuacion'] >= 4]\n",
    "    df_neg = df[df['puntuacion'] <= 2]\n",
    "    \n",
    "    print(f\"Reseñas positivas (4-5 estrellas): {len(df_pos)}\")\n",
    "    print(f\"Reseñas negativas (1-2 estrellas): {len(df_neg)}\")\n",
    "    \n",
    "    # Combinar textos por categoría\n",
    "    text_pos = ' '.join(df_pos['texto_sin_stopwords'].dropna().astype(str))\n",
    "    text_neg = ' '.join(df_neg['texto_sin_stopwords'].dropna().astype(str))\n",
    "    \n",
    "    # Contar frecuencias\n",
    "    tokens_pos = text_pos.split()\n",
    "    tokens_neg = text_neg.split()\n",
    "    \n",
    "    freq_pos = Counter(tokens_pos)\n",
    "    freq_neg = Counter(tokens_neg)\n",
    "    \n",
    "    # Mostrar palabras más características de cada categoría\n",
    "    print(\"\\nTop 5 palabras en reseñas POSITIVAS:\")\n",
    "    for word, count in freq_pos.most_common(5):\n",
    "        print(f\"  {word:15s}: {count:3d}\")\n",
    "    \n",
    "    print(\"\\nTop 5 palabras en reseñas NEGATIVAS:\")\n",
    "    for word, count in freq_neg.most_common(5):\n",
    "        print(f\"  {word:15s}: {count:3d}\")\n",
    "\n",
    "# %%\n",
    "# 2. ANÁLISIS DE SENTIMIENTO\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. ANÁLISIS DE SENTIMIENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def analyze_sentiment_textblob(text):\n",
    "    \"\"\"Analiza sentimiento usando TextBlob\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {'polarity': 0, 'subjectivity': 0, 'sentiment': 'neutral'}\n",
    "    \n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    subjectivity = analysis.sentiment.subjectivity\n",
    "    \n",
    "    # Clasificar sentimiento\n",
    "    if polarity > 0.1:\n",
    "        sentiment = 'positivo'\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = 'negativo'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    \n",
    "    return {\n",
    "        'polarity': polarity,\n",
    "        'subjectivity': subjectivity,\n",
    "        'sentiment': sentiment\n",
    "    }\n",
    "\n",
    "# Aplicar análisis de sentimiento a cada texto limpio\n",
    "print(\"Analizando sentimiento de las reseñas...\")\n",
    "sentiment_results = []\n",
    "\n",
    "for idx, text in enumerate(df['texto_limpio']):\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"  Procesando reseña {idx}/{len(df)}...\")\n",
    "    \n",
    "    result = analyze_sentiment_textblob(str(text))\n",
    "    sentiment_results.append(result)\n",
    "\n",
    "# Añadir resultados al DataFrame\n",
    "df_sentiment = df.copy()\n",
    "for key in ['polarity', 'subjectivity', 'sentiment']:\n",
    "    df_sentiment[key] = [result[key] for result in sentiment_results]\n",
    "\n",
    "# %%\n",
    "# Estadísticas de sentimiento\n",
    "print(\"\\nESTADÍSTICAS DE ANÁLISIS DE SENTIMIENTO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "sentiment_counts = df_sentiment['sentiment'].value_counts()\n",
    "print(\"\\nDistribución de sentimientos:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = count / len(df_sentiment) * 100\n",
    "    print(f\"  {sentiment:10s}: {count:3d} reseñas ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPolaridad promedio: {df_sentiment['polarity'].mean():.3f}\")\n",
    "print(f\"Subjetividad promedio: {df_sentiment['subjectivity'].mean():.3f}\")\n",
    "\n",
    "# %%\n",
    "# Comparación sentimiento vs puntuación\n",
    "if 'puntuacion' in df_sentiment.columns and df_sentiment['puntuacion'].notna().any():\n",
    "    print(\"\\nCOMPARACIÓN SENTIMIENTO VS PUNTUACIÓN\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Crear tabla cruzada\n",
    "    cross_tab = pd.crosstab(df_sentiment['puntuacion'], df_sentiment['sentiment'])\n",
    "    print(\"\\nTabla cruzada (Puntuación × Sentimiento):\")\n",
    "    print(cross_tab)\n",
    "    \n",
    "    # Calcular correlación\n",
    "    correlation = df_sentiment[['puntuacion', 'polarity']].corr().iloc[0, 1]\n",
    "    print(f\"\\nCorrelación puntuación-polaridad: {correlation:.3f}\")\n",
    "\n",
    "# %%\n",
    "# 3. ANÁLISIS ADICIONALES DE VALOR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. ANÁLISIS ADICIONALES DE VALOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Análisis de emociones básico (basado en léxico de emociones)\n",
    "print(\"\\nANÁLISIS DE EMOCIONES BÁSICO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Diccionario simple de emociones en español\n",
    "emotion_lexicon = {\n",
    "    'positivas': {\n",
    "        'bien', 'bueno', 'excelente', 'perfecto', 'genial', 'fantástico',\n",
    "        'maravilloso', 'recomiendo', 'recomendable', 'satisfecho', 'contento',\n",
    "        'feliz', 'rápido', 'fácil', 'útil', 'eficiente'\n",
    "    },\n",
    "    'negativas': {\n",
    "        'mal', 'malo', 'horrible', 'terrible', 'pésimo', 'decepcionado',\n",
    "        'decepción', 'problema', 'error', 'lento', 'difícil', 'complicado',\n",
    "        'caro', 'carísimo', 'devolver', 'reembolso', 'queja'\n",
    "    },\n",
    "    'neutras': {\n",
    "        'producto', 'servicio', 'entrega', 'pedido', 'cliente', 'atención',\n",
    "        'calidad', 'precio', 'tiempo', 'día', 'semana'\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_emotions(text):\n",
    "    \"\"\"Detección básica de emociones en el texto\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    emotions_detected = {'positivas': 0, 'negativas': 0, 'neutras': 0}\n",
    "    \n",
    "    for category, words in emotion_lexicon.items():\n",
    "        for word in words:\n",
    "            if word in text_lower:\n",
    "                emotions_detected[category] += 1\n",
    "    \n",
    "    # Determinar emoción predominante\n",
    "    max_count = max(emotions_detected.values())\n",
    "    if max_count == 0:\n",
    "        return 'sin_emocion_detectada'\n",
    "    \n",
    "    for category, count in emotions_detected.items():\n",
    "        if count == max_count:\n",
    "            return category\n",
    "\n",
    "# Aplicar detección de emociones\n",
    "df_sentiment['emocion_predominante'] = df_sentiment['texto_limpio'].apply(detect_emotions)\n",
    "\n",
    "# Estadísticas de emociones\n",
    "print(\"\\nDistribución de emociones detectadas:\")\n",
    "emotion_counts = df_sentiment['emocion_predominante'].value_counts()\n",
    "for emotion, count in emotion_counts.items():\n",
    "    percentage = count / len(df_sentiment) * 100\n",
    "    print(f\"  {emotion:25s}: {count:3d} reseñas ({percentage:.1f}%)\")\n",
    "\n",
    "# %%\n",
    "# Análisis de longitud vs sentimiento\n",
    "print(\"\\nANÁLISIS DE LONGITUD VS SENTIMIENTO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Calcular longitud de textos\n",
    "df_sentiment['longitud_texto'] = df_sentiment['texto_limpio'].apply(len)\n",
    "df_sentiment['num_palabras'] = df_sentiment['texto_limpio'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Estadísticas por sentimiento\n",
    "print(\"\\nEstadísticas por tipo de sentimiento:\")\n",
    "sentiment_groups = df_sentiment.groupby('sentiment')\n",
    "\n",
    "for sentiment, group in sentiment_groups:\n",
    "    print(f\"\\n{sentiment.upper()}:\")\n",
    "    print(f\"  Número de reseñas: {len(group)}\")\n",
    "    print(f\"  Longitud promedio: {group['longitud_texto'].mean():.0f} caracteres\")\n",
    "    print(f\"  Palabras promedio: {group['num_palabras'].mean():.0f}\")\n",
    "    if 'puntuacion' in group.columns:\n",
    "        print(f\"  Puntuación promedio: {group['puntuacion'].mean():.1f}\")\n",
    "\n",
    "# %%\n",
    "# Guardar resultados del análisis\n",
    "print(\"\\nGuardando resultados del análisis...\")\n",
    "\n",
    "# Guardar DataFrame con análisis de sentimiento\n",
    "output_path = '../data/processed/reviews_with_sentiment.csv'\n",
    "df_sentiment.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"✓ Dataset con sentimiento guardado: {output_path}\")\n",
    "\n",
    "# Guardar estadísticas clave\n",
    "stats = {\n",
    "    'total_resenas': len(df_sentiment),\n",
    "    'polaridad_promedio': float(df_sentiment['polarity'].mean()),\n",
    "    'subjetividad_promedio': float(df_sentiment['subjectivity'].mean()),\n",
    "    'distribucion_sentimientos': df_sentiment['sentiment'].value_counts().to_dict(),\n",
    "    'top_palabras': dict(word_freq.most_common(20)),\n",
    "    'correlacion_puntuacion_polaridad': float(correlation) if 'correlation' in locals() else None\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/processed/analisis_stats.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ Estadísticas guardadas: ../data/processed/analisis_stats.json\")\n",
    "\n",
    "# %%\n",
    "# Preparar datos para visualización\n",
    "print(\"\\nPreparando datos para visualización...\")\n",
    "\n",
    "# Crear dataset para visualización\n",
    "viz_data = df_sentiment[[\n",
    "    'titulo', 'texto_original', 'texto_limpio', 'puntuacion',\n",
    "    'polarity', 'subjectivity', 'sentiment', 'emocion_predominante',\n",
    "    'longitud_texto', 'num_palabras'\n",
    "]].copy()\n",
    "\n",
    "# Añadir información de frecuencia de palabras\n",
    "word_freq_df = pd.DataFrame(word_freq.most_common(50), columns=['palabra', 'frecuencia'])\n",
    "word_freq_df.to_csv('../data/processed/top_palabras.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Top 50 palabras guardadas: ../data/processed/top_palabras.csv\")\n",
    "\n",
    "# %%\n",
    "# Resumen del análisis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DEL ANÁLISIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Reseñas analizadas: {len(df_sentiment)}\")\n",
    "print(f\"✓ Sentimiento predominante: {df_sentiment['sentiment'].value_counts().idxmax()}\")\n",
    "print(f\"✓ Polaridad promedio: {df_sentiment['polarity'].mean():.3f}\")\n",
    "print(f\"✓ Palabras únicas identificadas: {len(word_freq)}\")\n",
    "print(f\"✓ Archivos generados:\")\n",
    "print(f\"   - reviews_with_sentiment.csv (dataset completo con análisis)\")\n",
    "print(f\"   - top_palabras.csv (frecuencia de palabras)\")\n",
    "print(f\"   - analisis_stats.json (estadísticas clave)\")\n",
    "print(\"\\nEl análisis está listo para la fase de visualización.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
