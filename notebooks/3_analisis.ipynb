{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791dbea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # FASE 3: Análisis de Valor\n",
    "# ## Persona A - Análisis de Frecuencia y Sentimiento\n",
    "\n",
    "# %%\n",
    "# Instalación de dependencias adicionales\n",
    "# !pip install textblob wordcloud\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# %%\n",
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# %%\n",
    "# Cargar datos procesados\n",
    "print(\"Cargando datos procesados...\")\n",
    "df = pd.read_csv('../data/processed/reviews_for_analysis.csv')\n",
    "print(f\"Dataset cargado: {len(df)} reseñas\")\n",
    "print(f\"Columnas disponibles: {list(df.columns)}\")\n",
    "\n",
    "# %%\n",
    "# 1. ANÁLISIS DE FRECUENCIA DE PALABRAS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. ANÁLISIS DE FRECUENCIA DE PALABRAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combinar todos los textos sin stopwords\n",
    "all_text = ' '.join(df['texto_sin_stopwords'].dropna().astype(str))\n",
    "\n",
    "# Tokenizar y contar frecuencia\n",
    "tokens = all_text.split()\n",
    "word_freq = Counter(tokens)\n",
    "\n",
    "print(f\"Total de palabras únicas: {len(word_freq)}\")\n",
    "print(f\"Total de tokens: {len(tokens)}\")\n",
    "\n",
    "# Top 20 palabras más frecuentes\n",
    "top_n = 20\n",
    "top_words = word_freq.most_common(top_n)\n",
    "\n",
    "print(f\"\\nTop {top_n} palabras más frecuentes:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (word, count) in enumerate(top_words, 1):\n",
    "    print(f\"{i:2d}. {word:20s} : {count:4d} apariciones\")\n",
    "\n",
    "# %%\n",
    "# Análisis por n-gramas (bigramas y trigramas)\n",
    "print(\"\\nANÁLISIS DE N-GRAMAS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "# Crear bigramas\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq = Counter(bigrams)\n",
    "\n",
    "# Top 10 bigramas\n",
    "print(\"\\nTop 10 bigramas más frecuentes:\")\n",
    "for i, (bigram, count) in enumerate(bigram_freq.most_common(10), 1):\n",
    "    print(f\"{i:2d}. {' '.join(bigram):30s} : {count:3d}\")\n",
    "\n",
    "# Crear trigramas\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "trigram_freq = Counter(trigrams)\n",
    "\n",
    "# Top 10 trigramas\n",
    "print(\"\\nTop 10 trigramas más frecuentes:\")\n",
    "for i, (trigram, count) in enumerate(trigram_freq.most_common(10), 1):\n",
    "    print(f\"{i:2d}. {' '.join(trigram):40s} : {count:3d}\")\n",
    "\n",
    "# %%\n",
    "# Análisis de frecuencia por puntuación\n",
    "print(\"\\nANÁLISIS DE FRECUENCIA POR PUNTUACIÓN\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'puntuacion' in df.columns and df['puntuacion'].notna().any():\n",
    "    # Separar reseñas positivas (4-5 estrellas) vs negativas (1-2 estrellas)\n",
    "    df_pos = df[df['puntuacion'] >= 4]\n",
    "    df_neg = df[df['puntuacion'] <= 2]\n",
    "    \n",
    "    print(f\"Reseñas positivas (4-5 estrellas): {len(df_pos)}\")\n",
    "    print(f\"Reseñas negativas (1-2 estrellas): {len(df_neg)}\")\n",
    "    \n",
    "    # Combinar textos por categoría\n",
    "    text_pos = ' '.join(df_pos['texto_sin_stopwords'].dropna().astype(str))\n",
    "    text_neg = ' '.join(df_neg['texto_sin_stopwords'].dropna().astype(str))\n",
    "    \n",
    "    # Contar frecuencias\n",
    "    tokens_pos = text_pos.split()\n",
    "    tokens_neg = text_neg.split()\n",
    "    \n",
    "    freq_pos = Counter(tokens_pos)\n",
    "    freq_neg = Counter(tokens_neg)\n",
    "    \n",
    "    # Mostrar palabras más características de cada categoría\n",
    "    print(\"\\nTop 5 palabras en reseñas POSITIVAS:\")\n",
    "    for word, count in freq_pos.most_common(5):\n",
    "        print(f\"  {word:15s}: {count:3d}\")\n",
    "    \n",
    "    print(\"\\nTop 5 palabras en reseñas NEGATIVAS:\")\n",
    "    for word, count in freq_neg.most_common(5):\n",
    "        print(f\"  {word:15s}: {count:3d}\")\n",
    "\n",
    "# %%\n",
    "# 2. ANÁLISIS DE SENTIMIENTO\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. ANÁLISIS DE SENTIMIENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def analyze_sentiment_textblob(text):\n",
    "    \"\"\"Analiza sentimiento usando TextBlob\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {'polarity': 0, 'subjectivity': 0, 'sentiment': 'neutral'}\n",
    "    \n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    subjectivity = analysis.sentiment.subjectivity\n",
    "    \n",
    "    # Clasificar sentimiento\n",
    "    if polarity > 0.1:\n",
    "        sentiment = 'positivo'\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = 'negativo'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    \n",
    "    return {\n",
    "        'polarity': polarity,\n",
    "        'subjectivity': subjectivity,\n",
    "        'sentiment': sentiment\n",
    "    }\n",
    "\n",
    "# Aplicar análisis de sentimiento a cada texto limpio\n",
    "print(\"Analizando sentimiento de las reseñas...\")\n",
    "sentiment_results = []\n",
    "\n",
    "for idx, text in enumerate(df['texto_limpio']):\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"  Procesando reseña {idx}/{len(df)}...\")\n",
    "    \n",
    "    result = analyze_sentiment_textblob(str(text))\n",
    "    sentiment_results.append(result)\n",
    "\n",
    "# Añadir resultados al DataFrame\n",
    "df_sentiment = df.copy()\n",
    "for key in ['polarity', 'subjectivity', 'sentiment']:\n",
    "    df_sentiment[key] = [result[key] for result in sentiment_results]\n",
    "\n",
    "# %%\n",
    "# Estadísticas de sentimiento\n",
    "print(\"\\nESTADÍSTICAS DE ANÁLISIS DE SENTIMIENTO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "sentiment_counts = df_sentiment['sentiment'].value_counts()\n",
    "print(\"\\nDistribución de sentimientos:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = count / len(df_sentiment) * 100\n",
    "    print(f\"  {sentiment:10s}: {count:3d} reseñas ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPolaridad promedio: {df_sentiment['polarity'].mean():.3f}\")\n",
    "print(f\"Subjetividad promedio: {df_sentiment['subjectivity'].mean():.3f}\")\n",
    "\n",
    "# %%\n",
    "# Comparación sentimiento vs puntuación\n",
    "if 'puntuacion' in df_sentiment.columns and df_sentiment['puntuacion'].notna().any():\n",
    "    print(\"\\nCOMPARACIÓN SENTIMIENTO VS PUNTUACIÓN\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Crear tabla cruzada\n",
    "    cross_tab = pd.crosstab(df_sentiment['puntuacion'], df_sentiment['sentiment'])\n",
    "    print(\"\\nTabla cruzada (Puntuación × Sentimiento):\")\n",
    "    print(cross_tab)\n",
    "    \n",
    "    # Calcular correlación\n",
    "    correlation = df_sentiment[['puntuacion', 'polarity']].corr().iloc[0, 1]\n",
    "    print(f\"\\nCorrelación puntuación-polaridad: {correlation:.3f}\")\n",
    "\n",
    "# %%\n",
    "# 3. ANÁLISIS ADICIONALES DE VALOR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. ANÁLISIS ADICIONALES DE VALOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Análisis de emociones básico (basado en léxico de emociones)\n",
    "print(\"\\nANÁLISIS DE EMOCIONES BÁSICO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Diccionario simple de emociones en español\n",
    "emotion_lexicon = {\n",
    "    'positivas': {\n",
    "        'bien', 'bueno', 'excelente', 'perfecto', 'genial', 'fantástico',\n",
    "        'maravilloso', 'recomiendo', 'recomendable', 'satisfecho', 'contento',\n",
    "        'feliz', 'rápido', 'fácil', 'útil', 'eficiente'\n",
    "    },\n",
    "    'negativas': {\n",
    "        'mal', 'malo', 'horrible', 'terrible', 'pésimo', 'decepcionado',\n",
    "        'decepción', 'problema', 'error', 'lento', 'difícil', 'complicado',\n",
    "        'caro', 'carísimo', 'devolver', 'reembolso', 'queja'\n",
    "    },\n",
    "    'neutras': {\n",
    "        'producto', 'servicio', 'entrega', 'pedido', 'cliente', 'atención',\n",
    "        'calidad', 'precio', 'tiempo', 'día', 'semana'\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_emotions(text):\n",
    "    \"\"\"Detección básica de emociones en el texto\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    emotions_detected = {'positivas': 0, 'negativas': 0, 'neutras': 0}\n",
    "    \n",
    "    for category, words in emotion_lexicon.items():\n",
    "        for word in words:\n",
    "            if word in text_lower:\n",
    "                emotions_detected[category] += 1\n",
    "    \n",
    "    # Determinar emoción predominante\n",
    "    max_count = max(emotions_detected.values())\n",
    "    if max_count == 0:\n",
    "        return 'sin_emocion_detectada'\n",
    "    \n",
    "    for category, count in emotions_detected.items():\n",
    "        if count == max_count:\n",
    "            return category\n",
    "\n",
    "# Aplicar detección de emociones\n",
    "df_sentiment['emocion_predominante'] = df_sentiment['texto_limpio'].apply(detect_emotions)\n",
    "\n",
    "# Estadísticas de emociones\n",
    "print(\"\\nDistribución de emociones detectadas:\")\n",
    "emotion_counts = df_sentiment['emocion_predominante'].value_counts()\n",
    "for emotion, count in emotion_counts.items():\n",
    "    percentage = count / len(df_sentiment) * 100\n",
    "    print(f\"  {emotion:25s}: {count:3d} reseñas ({percentage:.1f}%)\")\n",
    "\n",
    "# %%\n",
    "# Análisis de longitud vs sentimiento\n",
    "print(\"\\nANÁLISIS DE LONGITUD VS SENTIMIENTO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Calcular longitud de textos\n",
    "df_sentiment['longitud_texto'] = df_sentiment['texto_limpio'].apply(len)\n",
    "df_sentiment['num_palabras'] = df_sentiment['texto_limpio'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Estadísticas por sentimiento\n",
    "print(\"\\nEstadísticas por tipo de sentimiento:\")\n",
    "sentiment_groups = df_sentiment.groupby('sentiment')\n",
    "\n",
    "for sentiment, group in sentiment_groups:\n",
    "    print(f\"\\n{sentiment.upper()}:\")\n",
    "    print(f\"  Número de reseñas: {len(group)}\")\n",
    "    print(f\"  Longitud promedio: {group['longitud_texto'].mean():.0f} caracteres\")\n",
    "    print(f\"  Palabras promedio: {group['num_palabras'].mean():.0f}\")\n",
    "    if 'puntuacion' in group.columns:\n",
    "        print(f\"  Puntuación promedio: {group['puntuacion'].mean():.1f}\")\n",
    "\n",
    "# %%\n",
    "# Guardar resultados del análisis\n",
    "print(\"\\nGuardando resultados del análisis...\")\n",
    "\n",
    "# Guardar DataFrame con análisis de sentimiento\n",
    "output_path = '../data/processed/reviews_with_sentiment.csv'\n",
    "df_sentiment.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"✓ Dataset con sentimiento guardado: {output_path}\")\n",
    "\n",
    "# Guardar estadísticas clave\n",
    "stats = {\n",
    "    'total_resenas': len(df_sentiment),\n",
    "    'polaridad_promedio': float(df_sentiment['polarity'].mean()),\n",
    "    'subjetividad_promedio': float(df_sentiment['subjectivity'].mean()),\n",
    "    'distribucion_sentimientos': df_sentiment['sentiment'].value_counts().to_dict(),\n",
    "    'top_palabras': dict(word_freq.most_common(20)),\n",
    "    'correlacion_puntuacion_polaridad': float(correlation) if 'correlation' in locals() else None\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/processed/analisis_stats.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ Estadísticas guardadas: ../data/processed/analisis_stats.json\")\n",
    "\n",
    "# %%\n",
    "# Preparar datos para visualización\n",
    "print(\"\\nPreparando datos para visualización...\")\n",
    "\n",
    "# Crear dataset para visualización\n",
    "viz_data = df_sentiment[[\n",
    "    'titulo', 'texto_original', 'texto_limpio', 'puntuacion',\n",
    "    'polarity', 'subjectivity', 'sentiment', 'emocion_predominante',\n",
    "    'longitud_texto', 'num_palabras'\n",
    "]].copy()\n",
    "\n",
    "# Añadir información de frecuencia de palabras\n",
    "word_freq_df = pd.DataFrame(word_freq.most_common(50), columns=['palabra', 'frecuencia'])\n",
    "word_freq_df.to_csv('../data/processed/top_palabras.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Top 50 palabras guardadas: ../data/processed/top_palabras.csv\")\n",
    "\n",
    "# %%\n",
    "# Resumen del análisis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DEL ANÁLISIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Reseñas analizadas: {len(df_sentiment)}\")\n",
    "print(f\"✓ Sentimiento predominante: {df_sentiment['sentiment'].value_counts().idxmax()}\")\n",
    "print(f\"✓ Polaridad promedio: {df_sentiment['polarity'].mean():.3f}\")\n",
    "print(f\"✓ Palabras únicas identificadas: {len(word_freq)}\")\n",
    "print(f\"✓ Archivos generados:\")\n",
    "print(f\"   - reviews_with_sentiment.csv (dataset completo con análisis)\")\n",
    "print(f\"   - top_palabras.csv (frecuencia de palabras)\")\n",
    "print(f\"   - analisis_stats.json (estadísticas clave)\")\n",
    "print(\"\\nEl análisis está listo para la fase de visualización.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
